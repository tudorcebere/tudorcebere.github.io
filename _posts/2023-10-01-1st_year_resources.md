---
title: 'Resources I found useful as 1st year PhD student'
date: 2023-10-29
layout: post
tags:
  - learning resources
---
<!--more--> 
Below are some resources that helped me build a good foundation in probability, measure theory, and related topics in applied mathematics.

First, I revisited the basics of probability through [Stanford CS109](https://www.youtube.com/playlist?list=PLo4jXE-LdDTQq8ZyA8F8reSQHej3F6RFX). This course is a clear and concise introduction, which helped me recall essential concepts.

To dive deeper into theory, I watched the [Bright Side of Mathematics Measure Theory course](https://www.youtube.com/playlist?list=PLBh2i93oe2quIJS-j1NpbzEvQCmN00F5o). It does a great job explaining *why* measure theory is important, which motivated me to keep learning. I also recommend [Professor Lanchier’s Advanced Probability](https://www.youtube.com/watch?v=qGsHiHwgInU&list=PLV3oHJg9b1NRhjCs7ZgkAj6US-8m2ymTB) and [Claudio Landim’s Measure Theory course](https://www.youtube.com/playlist?list=PLo4jXE-LdDTQq8ZyA8F8reSQHej3F6RFX) for a more detailed approach.

After covering the basics, I looked at applications of probability in different fields. [Markov Processes by J.N. Corcoran](https://www.youtube.com/watch?v=9otUB3WXB8E&list=PLLyj1Zd4UWrP3rME2XvFvE4Q5vI3H_7_Z) is an easy-to-follow introduction to many core ideas in applied probability, and Corcoran’s [Mathematical Statistics](https://www.youtube.com/watch?v=ELgjmaSGsWs&list=PLLyj1Zd4UWrOk5-wIki_oOxHJnNj0_437) lays out key topics from statistics. [R. Vershynin’s High Dimensional Probability](https://www.math.uci.edu/~rvershyn/teaching/hdp/hdp.html) is a bit more advanced but offers a introduction to key tools like concentration inequalities and highdimensional tools in probability. If you want a solid introduction to theoretical machine learning, [S.B. David’s Learning Theory](https://www.youtube.com/watch?v=b5NlRg8SjZg&list=PLPW2keNyw-usgvmR7FTQ3ZRjfLs5jT4BO) is excellent.

Since ideas from information theory show up in both machine learning and differential privacy, I decided to study [D. MacKay’s Information Theory, pattern recognition and neural networks](https://www.youtube.com/watch?v=BCiZc0n6COY&list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6) along with the book from the same author.

When it comes to understanding differential privacy, [G. Kamath’s Differential Privacy](https://www.youtube.com/watch?v=FJMjNOcIqkc&list=PLmd_zeMNzSvRRNpoEWkVo6QY_6rR3SHjp) is a clear introduction to this field. Another course that I found fascinating was [J. Nelson’s Sketching Algorithms](https://sketchingbigdata.org/fall20/lec/), which covers a wide range of advanced topics in probabilistic algorithms. If you need optimization methods for machine learning (which can also apply to differential privacy!), check out [M. Jaggi’s Optimization for Machine Learning](https://www.youtube.com/playlist?list=PL4O4bXkI-fAeYrsBqTUYn2xMjJAqlFQzX).

Strong writing skills are important for sharing ideas. I found [The Elements of Style](https://www.bartleby.com/lit-hub/the-elements-of-style) and [How to write a great paper by S.P. Jones](https://www.microsoft.com/en-us/research/academic-program/write-great-resepuarch-paper/) helpful for improving my writing style. I also enjoyed reading Oded Goldreich’s blog, such as [How to write a paper](https://www.wisdom.weizmann.ac.il/~oded/writing.html) and [On the emotional difficulty of conducting research](https://www.wisdom.weizmann.ac.il/~oded/on-ideas.html). These pieces made me more aware of both the technical and personal sides of research.